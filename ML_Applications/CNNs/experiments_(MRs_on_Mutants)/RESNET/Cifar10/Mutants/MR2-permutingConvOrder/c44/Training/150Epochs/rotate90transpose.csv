step, cross_entropy, loss, train_accuracy
1,2.65588,2.86795,0.0703125
101,2.43036,2.64243,0.105469
201,2.56572,2.7778,0.0963542
301,2.55231,2.76439,0.101563
394,2.65588,2.86795,0.0703125
494,2.43036,2.64243,0.105469
594,2.56572,2.7778,0.0963542
694,2.55231,2.76439,0.101563
787,2.65588,2.86795,0.0703125
887,2.43036,2.64243,0.105469
987,2.56572,2.7778,0.0963542
1087,2.55231,2.76439,0.101563
1180,2.65588,2.86795,0.0703125
1280,2.43036,2.64243,0.105469
1380,2.56572,2.7778,0.0963542
1480,2.55231,2.76439,0.101563
1573,2.65588,2.86795,0.0703125
1673,2.43036,2.64243,0.105469
1773,2.56572,2.7778,0.0963542
1873,2.55231,2.76439,0.101563
1966,2.65588,2.86795,0.0703125
2066,2.43036,2.64243,0.105469
2166,2.56572,2.7778,0.0963542
2266,2.55231,2.76439,0.101563
2359,2.65588,2.86795,0.0703125
2459,2.43036,2.64243,0.105469
2559,2.56572,2.7778,0.0963542
2659,2.55231,2.76439,0.101563
2752,2.65588,2.86795,0.0703125
2852,2.43036,2.64243,0.105469
2952,2.56572,2.7778,0.0963542
3052,2.55231,2.76439,0.101563
3145,2.65588,2.86795,0.0703125
3245,2.43036,2.64243,0.105469
3345,2.56572,2.7778,0.0963542
3445,2.55231,2.76439,0.101563
3538,2.65588,2.86795,0.0703125
3638,2.43036,2.64243,0.105469
3738,2.56572,2.7778,0.0963542
3838,2.55231,2.76439,0.101563
3931,5.25107,5.47249,0.109375
4031,2.35454,6.63591,0.109375
4131,2.15787,5.00974,0.119792
4231,2.19043,4.09705,0.134766
4324,2.09369,3.40695,0.210938
4424,2.01865,2.90228,0.207031
4524,1.93277,2.53553,0.216146
4624,2.02532,2.44352,0.210938
4717,1.80208,2.11318,0.296875
4817,1.84116,2.08282,0.292969
4917,1.6437,1.84837,0.317708
5017,1.57627,1.76391,0.333984
5110,1.47757,1.66482,0.453125
5210,1.49763,1.69236,0.453125
5310,1.39538,1.60632,0.453125
5410,1.19271,1.42353,0.488281
5503,1.15315,1.39812,0.554688
5603,1.26942,1.53049,0.527344
5703,1.28961,1.56619,0.539063
5803,1.17982,1.46826,0.558594
