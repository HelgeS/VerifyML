step, cross_entropy, loss, train_accuracy
1,2.6468,2.85887,0.0703125
101,2.41556,2.62763,0.105469
201,2.57608,2.78816,0.0963542
301,2.56662,2.7787,0.101563
394,2.6468,2.85887,0.0703125
494,2.41556,2.62763,0.105469
594,2.57608,2.78816,0.0963542
694,2.56662,2.7787,0.101563
787,2.6468,2.85887,0.0703125
887,2.41556,2.62763,0.105469
987,2.57608,2.78816,0.0963542
1087,2.56662,2.7787,0.101563
1180,2.6468,2.85887,0.0703125
1280,2.41556,2.62763,0.105469
1380,2.57608,2.78816,0.0963542
1480,2.56662,2.7787,0.101563
1573,2.6468,2.85887,0.0703125
1673,2.41556,2.62763,0.105469
1773,2.57608,2.78816,0.0963542
1873,2.56662,2.7787,0.101563
1966,2.6468,2.85887,0.0703125
2066,2.41556,2.62763,0.105469
2166,2.57608,2.78816,0.0963542
2266,2.56662,2.7787,0.101563
2359,2.6468,2.85887,0.0703125
2459,2.41556,2.62763,0.105469
2559,2.57608,2.78816,0.0963542
2659,2.56662,2.7787,0.101563
2752,2.6468,2.85887,0.0703125
2852,2.41556,2.62763,0.105469
2952,2.57608,2.78816,0.0963542
3052,2.56662,2.7787,0.101563
3145,2.6468,2.85887,0.0703125
3245,2.41556,2.62763,0.105469
3345,2.57608,2.78816,0.0963542
3445,2.56662,2.7787,0.101563
3538,2.6468,2.85887,0.0703125
3638,2.41556,2.62763,0.105469
3738,2.57608,2.78816,0.0963542
3838,2.56662,2.7787,0.101563
3931,4.96877,5.18958,0.117188
4031,2.36765,3.73652,0.101563
4131,2.31905,3.22953,0.0989583
4231,2.31982,2.92533,0.0976563
4324,2.32286,2.73724,0.140625
4424,2.3664,2.64201,0.113281
4524,2.31906,2.50234,0.106771
4624,2.31982,2.44172,0.103516
4717,2.32286,2.4063,0.140625
4817,2.3664,2.42192,0.113281
4917,2.31906,2.35597,0.106771
5017,2.31982,2.34437,0.103516
5110,2.32286,2.33968,0.140625
5210,2.3664,2.37762,0.113281
5310,2.31906,2.32651,0.106771
5410,2.31982,2.32478,0.103516
5503,2.32286,2.32628,0.140625
5603,2.3664,2.3687,0.113281
5703,2.31906,2.32058,0.106771
5803,2.31982,2.32084,0.103516
